{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APS Failure at Scania Trucks\n",
    "\n",
    "It seems like a lot of the classification tasks worth pursuing have low (< 5%) target prevalence, and in many of those tasks, there are a large number of both categorical and continuous predictors. In this notebook, I'll walk through a variety of approaches for dealing with unbalanced datasets.\n",
    "\n",
    "## Data Description\n",
    "`aps_failure_test_set.csv`: 11.9MB (16,000 obs)\n",
    "\n",
    "`aps_failure_training_set.csv`: 44.7MB (60,000 obs)\n",
    "\n",
    "The datasets' positive class consists of component failures for a specific component of the APS system. The negative class consists of trucks with failures for components not related to the APS.\n",
    "\n",
    "The attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like `Identifier_Bin`. In total there are 171 attributes, of which 7 are histogram variables. Missing values are denoted by `na`.\n",
    "\n",
    "## Challenge Metric\n",
    "Since this dataset was part of a challenge, they also provided a \"challenge metric\" formula to weight the cost of false positives and false negatives:\n",
    "\n",
    "`Cost_1(FP) = 10` and `cost_2(FN) = 500`\n",
    "\n",
    "We will want to minimize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_true, y_pred, fp_cost=10, fn_cost=500, normalize=True):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fp = cm[1][1]\n",
    "    fn = cm[0][1]\n",
    "    \n",
    "    c = fp * fp_cost + fn * fn_cost\n",
    "    \n",
    "    return c / len(y_true) if normalize else c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>76698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520.0</td>\n",
       "      <td>493384.0</td>\n",
       "      <td>721044.0</td>\n",
       "      <td>469792.0</td>\n",
       "      <td>339156.0</td>\n",
       "      <td>157956.0</td>\n",
       "      <td>73224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>33058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400.0</td>\n",
       "      <td>178064.0</td>\n",
       "      <td>293306.0</td>\n",
       "      <td>245416.0</td>\n",
       "      <td>133654.0</td>\n",
       "      <td>81140.0</td>\n",
       "      <td>97576.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>41040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.280000e+02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378.0</td>\n",
       "      <td>159812.0</td>\n",
       "      <td>423992.0</td>\n",
       "      <td>409564.0</td>\n",
       "      <td>320746.0</td>\n",
       "      <td>158022.0</td>\n",
       "      <td>95128.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>60874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.368000e+03</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012.0</td>\n",
       "      <td>229790.0</td>\n",
       "      <td>405298.0</td>\n",
       "      <td>347188.0</td>\n",
       "      <td>286954.0</td>\n",
       "      <td>311560.0</td>\n",
       "      <td>433954.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  aa_000  ab_000        ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
       "0   neg   76698     NaN  2.130706e+09   280.0     0.0     0.0     0.0     0.0   \n",
       "1   neg   33058     NaN  0.000000e+00     NaN     0.0     0.0     0.0     0.0   \n",
       "2   neg   41040     NaN  2.280000e+02   100.0     0.0     0.0     0.0     0.0   \n",
       "3   neg      12     0.0  7.000000e+01    66.0     0.0    10.0     0.0     0.0   \n",
       "4   neg   60874     NaN  1.368000e+03   458.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   ag_002  ...     ee_002    ee_003    ee_004    ee_005    ee_006    ee_007  \\\n",
       "0     0.0  ...  1240520.0  493384.0  721044.0  469792.0  339156.0  157956.0   \n",
       "1     0.0  ...   421400.0  178064.0  293306.0  245416.0  133654.0   81140.0   \n",
       "2     0.0  ...   277378.0  159812.0  423992.0  409564.0  320746.0  158022.0   \n",
       "3     0.0  ...      240.0      46.0      58.0      44.0      10.0       0.0   \n",
       "4     0.0  ...   622012.0  229790.0  405298.0  347188.0  286954.0  311560.0   \n",
       "\n",
       "     ee_008  ee_009  ef_000  eg_000  \n",
       "0   73224.0     0.0     0.0     0.0  \n",
       "1   97576.0  1500.0     0.0     0.0  \n",
       "2   95128.0   514.0     0.0     0.0  \n",
       "3       0.0     0.0     4.0    32.0  \n",
       "4  433954.0  1218.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('aps_failure_training_set.csv', header=14, na_values='na')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert target into a binary variable and rename column so it doesn't use a keyword (aka `class`) that prevents dot accessibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'] = train_df['class'].map({'neg': 0, 'pos': 1})\n",
    "train_df = train_df.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Generation\n",
    "I find it helpful to put together a metadata-set that describes important characteristics of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata(df):\n",
    "    meta = df.isnull().sum().to_frame('n_missing')\n",
    "    meta['perc_missing'] = meta['n_missing'] / len(df)\n",
    "    meta['n_unique'] = df.nunique()\n",
    "    \n",
    "    descs = train_df.describe().T\n",
    "    descs['n_valid'] = descs['count'].copy()\n",
    "    return meta.join(descs.drop('count', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = generate_metadata(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the cell below to view the metadata in its entirety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     display(meta.sort_values('perc_missing', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice about `meta`...\n",
    "\n",
    "- Everything is numeric. This is typical of UCI datasets, but normally, we would have to think about how to handle other types.\n",
    "- `cd_000` has only one unique value. We'll start by encoding it as a binary variable.\n",
    "\n",
    "For the baseline model, we will drop predictors that are over 25% missing and impute the median for the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove variables with > 25% missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_vars = meta[meta.perc_missing > 0.25].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.loc[:, ~train_df.columns.isin(bad_vars)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Dev Split\n",
    "We want to save the test set for an unbiased, out-of-sample assessment of the final model, so let's split the training data into a new training set and a development set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = namedtuple('Data', ['X_train', 'X_dev', 'y_train', 'y_dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(train_df.drop('target', axis=1), train_df.target, test_size=.2, stratify=train_df.target, random_state=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = namedtuple('Data', ['X_train', 'y_train'])\n",
    "data = Data(train_df.drop('target', axis=1), train_df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a baseline model\n",
    "\n",
    "Let's start by getting a baseline model with logistic regression with L1 and L2 regularization (default in `sklearn`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('lr', LogisticRegression(solver='lbfgs', random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(pl, data):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    costs = []\n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(data.X_train, data.y_train)):\n",
    "        X_train, y_train = data.X_train.iloc[train_idx], data.y_train.iloc[train_idx]\n",
    "        X_test, y_test = data.X_train.iloc[test_idx], data.y_train.iloc[test_idx]\n",
    "        pl.fit(X_train, y_train)\n",
    "        y_preds = pl.predict(X_test)\n",
    "        costs.append(cost(y_test, y_preds))\n",
    "    print(np.mean(costs))\n",
    "    \n",
    "    # train assessment\n",
    "#     y_preds = pl.predict(data.X_train)\n",
    "#     print('##### Train #####')\n",
    "#     print(classification_report(data.y_train, y_preds))\n",
    "#     print(f'Normalized train cost: {cost(data.y_train, y_preds):.{2}f}\\n')\n",
    "    \n",
    "    # dev assessment\n",
    "#     y_preds = pl.predict(data.X_dev)\n",
    "#     print('##### Test #####')\n",
    "#     print(classification_report(data.y_dev, y_preds))\n",
    "#     print(f'Normalized dev cost: {cost(data.y_dev, y_preds):.{2}f}\\n')\n",
    "    \n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/scania/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/anaconda3/envs/scania/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/anaconda3/envs/scania/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/anaconda3/envs/scania/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8802083333333333, 1.5645833333333334, 2.1375, 1.4625, 0.940625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/scania/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our baseline normalized cost for on the `dev` set is 1.44. Let's see if we can beat it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: ElasticNet\n",
    "I'm always confused about the difference between elastic net and logistic regression in `sklearn` because the logistic regression uses L1 and L2 regularization by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='elasticnet', random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8672916666666666\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet + Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='elasticnet', learning_rate='adaptive', eta0=0.1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.798125\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='l1', random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8579166666666667\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Regularization + Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='l1', learning_rate='adaptive', eta0=1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0727083333333334\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting....the L1-only model gives very similar results for both the train and dev sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Penality only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='l2', random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6983333333333335\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Penality + Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='l2', learning_rate='adaptive', eta0=1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9427083333333333\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No regularization + Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='none', learning_rate='adaptive', eta0=1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.382916666666667\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The elastic net model with learning rate adaptation significantly outperformed the baseline model based on the challenge metric. However, I am having some heartburn about the whole challenge metric optimization...is a false  positive really 50 times worse than a false negative???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8146666666666667\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm...this is the largest disparity in train/test cost that we've seen so far, which makes me think the model is overfit. I wonder if a RF would do better if we did some feature selection first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('selector', SelectFromModel(SGDClassifier(loss='log', penalty='elasticnet', learning_rate='adaptive', eta0=1, random_state=seed))),\n",
    "    ('rf', RandomForestClassifier(random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/scania/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629166666666666\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Predictive Imputation\n",
    "Let's see if we can get any lift out of the new `IterativeImputer` from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', IterativeImputer(ExtraTreesRegressor(random_state=seed, n_estimators=10), random_state=seed)),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran out of memory :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: ElasticNet Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='elasticnet', learning_rate='adaptive', eta0=1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1,  1. , 10. ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-1, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'en__eta0': np.logspace(-1, 1, 3),\n",
    "    'en__alpha': np.logspace(-1, 1, 3),\n",
    "    'en__l1_ratio': np.random.random_sample(3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pl, param_grid, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/scania/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed: 15.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('imputer',\n",
       "                                        SimpleImputer(add_indicator=False,\n",
       "                                                      copy=True,\n",
       "                                                      fill_value=None,\n",
       "                                                      missing_values=nan,\n",
       "                                                      strategy='median',\n",
       "                                                      verbose=0)),\n",
       "                                       ('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('en',\n",
       "                                        SGDClassifier(alpha=0.0001,\n",
       "                                                      average=False,\n",
       "                                                      class_weight=None,\n",
       "                                                      early_...\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=42,\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'en__alpha': array([ 0.1,  1. , 10. ]),\n",
       "                         'en__eta0': array([ 0.1,  1. , 10. ]),\n",
       "                         'en__l1_ratio': array([0.59063992, 0.75172948, 0.84014796])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(data.X_train, data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_en__alpha</th>\n",
       "      <th>param_en__eta0</th>\n",
       "      <th>param_en__l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.802815</td>\n",
       "      <td>0.162494</td>\n",
       "      <td>0.153891</td>\n",
       "      <td>0.020452</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.59064</td>\n",
       "      <td>{'en__alpha': 0.1, 'en__eta0': 0.1, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.938443</td>\n",
       "      <td>0.057334</td>\n",
       "      <td>0.125233</td>\n",
       "      <td>0.019003</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>{'en__alpha': 0.1, 'en__eta0': 0.1, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.847812</td>\n",
       "      <td>0.057905</td>\n",
       "      <td>0.124929</td>\n",
       "      <td>0.017362</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>{'en__alpha': 0.1, 'en__eta0': 0.1, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.386170</td>\n",
       "      <td>0.154293</td>\n",
       "      <td>0.105901</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59064</td>\n",
       "      <td>{'en__alpha': 0.1, 'en__eta0': 1.0, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.302342</td>\n",
       "      <td>0.060104</td>\n",
       "      <td>0.106760</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>{'en__alpha': 0.1, 'en__eta0': 1.0, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.069584</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>0.107690</td>\n",
       "      <td>0.021227</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>{'en__alpha': 0.1, 'en__eta0': 1.0, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.308473</td>\n",
       "      <td>0.402296</td>\n",
       "      <td>0.114809</td>\n",
       "      <td>0.026464</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.59064</td>\n",
       "      <td>{'en__alpha': 0.1, 'en__eta0': 10.0, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.217208</td>\n",
       "      <td>0.064072</td>\n",
       "      <td>0.107169</td>\n",
       "      <td>0.016717</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>{'en__alpha': 0.1, 'en__eta0': 10.0, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>103.532825</td>\n",
       "      <td>0.457535</td>\n",
       "      <td>0.372566</td>\n",
       "      <td>0.105444</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>{'en__alpha': 0.1, 'en__eta0': 10.0, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101.829350</td>\n",
       "      <td>0.031409</td>\n",
       "      <td>0.317255</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.59064</td>\n",
       "      <td>{'en__alpha': 1.0, 'en__eta0': 0.1, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70.471486</td>\n",
       "      <td>44.415242</td>\n",
       "      <td>0.254521</td>\n",
       "      <td>0.079345</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>{'en__alpha': 1.0, 'en__eta0': 0.1, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.313198</td>\n",
       "      <td>0.076826</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>0.015543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>{'en__alpha': 1.0, 'en__eta0': 0.1, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.814457</td>\n",
       "      <td>0.071312</td>\n",
       "      <td>0.124069</td>\n",
       "      <td>0.021091</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59064</td>\n",
       "      <td>{'en__alpha': 1.0, 'en__eta0': 1.0, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.573247</td>\n",
       "      <td>0.048058</td>\n",
       "      <td>0.121490</td>\n",
       "      <td>0.030779</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>{'en__alpha': 1.0, 'en__eta0': 1.0, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.744014</td>\n",
       "      <td>0.173784</td>\n",
       "      <td>0.148668</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>{'en__alpha': 1.0, 'en__eta0': 1.0, 'en__l1_ra...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.836050</td>\n",
       "      <td>0.234617</td>\n",
       "      <td>0.128520</td>\n",
       "      <td>0.032970</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.59064</td>\n",
       "      <td>{'en__alpha': 1.0, 'en__eta0': 10.0, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.844053</td>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.124376</td>\n",
       "      <td>0.027971</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>{'en__alpha': 1.0, 'en__eta0': 10.0, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.602059</td>\n",
       "      <td>0.127903</td>\n",
       "      <td>0.117452</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>{'en__alpha': 1.0, 'en__eta0': 10.0, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.640787</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>0.117665</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.59064</td>\n",
       "      <td>{'en__alpha': 10.0, 'en__eta0': 0.1, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.706545</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>0.110878</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>{'en__alpha': 10.0, 'en__eta0': 0.1, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.652053</td>\n",
       "      <td>0.025902</td>\n",
       "      <td>0.108299</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>{'en__alpha': 10.0, 'en__eta0': 0.1, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>494.530660</td>\n",
       "      <td>344.617120</td>\n",
       "      <td>0.100327</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59064</td>\n",
       "      <td>{'en__alpha': 10.0, 'en__eta0': 1.0, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>737.968270</td>\n",
       "      <td>0.104278</td>\n",
       "      <td>0.085768</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>{'en__alpha': 10.0, 'en__eta0': 1.0, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>737.523751</td>\n",
       "      <td>0.301905</td>\n",
       "      <td>0.091246</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>{'en__alpha': 10.0, 'en__eta0': 1.0, 'en__l1_r...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.759159</td>\n",
       "      <td>0.102708</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.59064</td>\n",
       "      <td>{'en__alpha': 10.0, 'en__eta0': 10.0, 'en__l1_...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.417045</td>\n",
       "      <td>0.111761</td>\n",
       "      <td>0.048443</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>{'en__alpha': 10.0, 'en__eta0': 10.0, 'en__l1_...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.412833</td>\n",
       "      <td>0.775094</td>\n",
       "      <td>0.044950</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>{'en__alpha': 10.0, 'en__eta0': 10.0, 'en__l1_...</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983374</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        7.802815      0.162494         0.153891        0.020452   \n",
       "1        6.938443      0.057334         0.125233        0.019003   \n",
       "2        6.847812      0.057905         0.124929        0.017362   \n",
       "3        8.386170      0.154293         0.105901        0.005236   \n",
       "4        7.302342      0.060104         0.106760        0.021663   \n",
       "5        7.069584      0.017117         0.107690        0.021227   \n",
       "6        9.308473      0.402296         0.114809        0.026464   \n",
       "7        8.217208      0.064072         0.107169        0.016717   \n",
       "8      103.532825      0.457535         0.372566        0.105444   \n",
       "9      101.829350      0.031409         0.317255        0.008041   \n",
       "10      70.471486     44.415242         0.254521        0.079345   \n",
       "11       7.313198      0.076826         0.111374        0.015543   \n",
       "12       7.814457      0.071312         0.124069        0.021091   \n",
       "13       7.573247      0.048058         0.121490        0.030779   \n",
       "14       7.744014      0.173784         0.148668        0.018939   \n",
       "15       8.836050      0.234617         0.128520        0.032970   \n",
       "16       8.844053      0.046081         0.124376        0.027971   \n",
       "17       8.602059      0.127903         0.117452        0.015940   \n",
       "18       6.640787      0.051802         0.117665        0.010883   \n",
       "19       6.706545      0.023299         0.110878        0.026803   \n",
       "20       6.652053      0.025902         0.108299        0.009940   \n",
       "21     494.530660    344.617120         0.100327        0.036393   \n",
       "22     737.968270      0.104278         0.085768        0.021082   \n",
       "23     737.523751      0.301905         0.091246        0.006327   \n",
       "24       5.759159      0.102708         0.065014        0.009123   \n",
       "25       5.417045      0.111761         0.048443        0.005429   \n",
       "26       4.412833      0.775094         0.044950        0.003437   \n",
       "\n",
       "   param_en__alpha param_en__eta0 param_en__l1_ratio  \\\n",
       "0              0.1            0.1            0.59064   \n",
       "1              0.1            0.1           0.751729   \n",
       "2              0.1            0.1           0.840148   \n",
       "3              0.1              1            0.59064   \n",
       "4              0.1              1           0.751729   \n",
       "5              0.1              1           0.840148   \n",
       "6              0.1             10            0.59064   \n",
       "7              0.1             10           0.751729   \n",
       "8              0.1             10           0.840148   \n",
       "9                1            0.1            0.59064   \n",
       "10               1            0.1           0.751729   \n",
       "11               1            0.1           0.840148   \n",
       "12               1              1            0.59064   \n",
       "13               1              1           0.751729   \n",
       "14               1              1           0.840148   \n",
       "15               1             10            0.59064   \n",
       "16               1             10           0.751729   \n",
       "17               1             10           0.840148   \n",
       "18              10            0.1            0.59064   \n",
       "19              10            0.1           0.751729   \n",
       "20              10            0.1           0.840148   \n",
       "21              10              1            0.59064   \n",
       "22              10              1           0.751729   \n",
       "23              10              1           0.840148   \n",
       "24              10             10            0.59064   \n",
       "25              10             10           0.751729   \n",
       "26              10             10           0.840148   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'en__alpha': 0.1, 'en__eta0': 0.1, 'en__l1_ra...           0.983314   \n",
       "1   {'en__alpha': 0.1, 'en__eta0': 0.1, 'en__l1_ra...           0.983314   \n",
       "2   {'en__alpha': 0.1, 'en__eta0': 0.1, 'en__l1_ra...           0.983314   \n",
       "3   {'en__alpha': 0.1, 'en__eta0': 1.0, 'en__l1_ra...           0.983314   \n",
       "4   {'en__alpha': 0.1, 'en__eta0': 1.0, 'en__l1_ra...           0.983314   \n",
       "5   {'en__alpha': 0.1, 'en__eta0': 1.0, 'en__l1_ra...           0.983314   \n",
       "6   {'en__alpha': 0.1, 'en__eta0': 10.0, 'en__l1_r...           0.983314   \n",
       "7   {'en__alpha': 0.1, 'en__eta0': 10.0, 'en__l1_r...           0.983314   \n",
       "8   {'en__alpha': 0.1, 'en__eta0': 10.0, 'en__l1_r...           0.983314   \n",
       "9   {'en__alpha': 1.0, 'en__eta0': 0.1, 'en__l1_ra...           0.983314   \n",
       "10  {'en__alpha': 1.0, 'en__eta0': 0.1, 'en__l1_ra...           0.983314   \n",
       "11  {'en__alpha': 1.0, 'en__eta0': 0.1, 'en__l1_ra...           0.983314   \n",
       "12  {'en__alpha': 1.0, 'en__eta0': 1.0, 'en__l1_ra...           0.983314   \n",
       "13  {'en__alpha': 1.0, 'en__eta0': 1.0, 'en__l1_ra...           0.983314   \n",
       "14  {'en__alpha': 1.0, 'en__eta0': 1.0, 'en__l1_ra...           0.983314   \n",
       "15  {'en__alpha': 1.0, 'en__eta0': 10.0, 'en__l1_r...           0.983314   \n",
       "16  {'en__alpha': 1.0, 'en__eta0': 10.0, 'en__l1_r...           0.983314   \n",
       "17  {'en__alpha': 1.0, 'en__eta0': 10.0, 'en__l1_r...           0.983314   \n",
       "18  {'en__alpha': 10.0, 'en__eta0': 0.1, 'en__l1_r...           0.983314   \n",
       "19  {'en__alpha': 10.0, 'en__eta0': 0.1, 'en__l1_r...           0.983314   \n",
       "20  {'en__alpha': 10.0, 'en__eta0': 0.1, 'en__l1_r...           0.983314   \n",
       "21  {'en__alpha': 10.0, 'en__eta0': 1.0, 'en__l1_r...           0.983314   \n",
       "22  {'en__alpha': 10.0, 'en__eta0': 1.0, 'en__l1_r...           0.983314   \n",
       "23  {'en__alpha': 10.0, 'en__eta0': 1.0, 'en__l1_r...           0.983314   \n",
       "24  {'en__alpha': 10.0, 'en__eta0': 10.0, 'en__l1_...           0.983314   \n",
       "25  {'en__alpha': 10.0, 'en__eta0': 10.0, 'en__l1_...           0.983314   \n",
       "26  {'en__alpha': 10.0, 'en__eta0': 10.0, 'en__l1_...           0.983314   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.983313           0.983374         0.983333        0.000029   \n",
       "1            0.983313           0.983374         0.983333        0.000029   \n",
       "2            0.983313           0.983374         0.983333        0.000029   \n",
       "3            0.983313           0.983374         0.983333        0.000029   \n",
       "4            0.983313           0.983374         0.983333        0.000029   \n",
       "5            0.983313           0.983374         0.983333        0.000029   \n",
       "6            0.983313           0.983374         0.983333        0.000029   \n",
       "7            0.983313           0.983374         0.983333        0.000029   \n",
       "8            0.983313           0.983374         0.983333        0.000029   \n",
       "9            0.983313           0.983374         0.983333        0.000029   \n",
       "10           0.983313           0.983374         0.983333        0.000029   \n",
       "11           0.983313           0.983374         0.983333        0.000029   \n",
       "12           0.983313           0.983374         0.983333        0.000029   \n",
       "13           0.983313           0.983374         0.983333        0.000029   \n",
       "14           0.983313           0.983374         0.983333        0.000029   \n",
       "15           0.983313           0.983374         0.983333        0.000029   \n",
       "16           0.983313           0.983374         0.983333        0.000029   \n",
       "17           0.983313           0.983374         0.983333        0.000029   \n",
       "18           0.983313           0.983374         0.983333        0.000029   \n",
       "19           0.983313           0.983374         0.983333        0.000029   \n",
       "20           0.983313           0.983374         0.983333        0.000029   \n",
       "21           0.983313           0.983374         0.983333        0.000029   \n",
       "22           0.983313           0.983374         0.983333        0.000029   \n",
       "23           0.983313           0.983374         0.983333        0.000029   \n",
       "24           0.983313           0.983374         0.983333        0.000029   \n",
       "25           0.983313           0.983374         0.983333        0.000029   \n",
       "26           0.983313           0.983374         0.983333        0.000029   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "5                 1  \n",
       "6                 1  \n",
       "7                 1  \n",
       "8                 1  \n",
       "9                 1  \n",
       "10                1  \n",
       "11                1  \n",
       "12                1  \n",
       "13                1  \n",
       "14                1  \n",
       "15                1  \n",
       "16                1  \n",
       "17                1  \n",
       "18                1  \n",
       "19                1  \n",
       "20                1  \n",
       "21                1  \n",
       "22                1  \n",
       "23                1  \n",
       "24                1  \n",
       "25                1  \n",
       "26                1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='elasticnet', learning_rate='adaptive', eta0=1, alpha=1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     47200\n",
      "           1       0.00      0.00      0.00       800\n",
      "\n",
      "    accuracy                           0.98     48000\n",
      "   macro avg       0.49      0.50      0.50     48000\n",
      "weighted avg       0.97      0.98      0.98     48000\n",
      "\n",
      "Normalized train cost: 0.00\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     11800\n",
      "           1       0.00      0.00      0.00       200\n",
      "\n",
      "    accuracy                           0.98     12000\n",
      "   macro avg       0.49      0.50      0.50     12000\n",
      "weighted avg       0.97      0.98      0.98     12000\n",
      "\n",
      "Normalized dev cost: 0.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/scania/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/anaconda3/envs/scania/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
