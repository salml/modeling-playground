{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APS Failure at Scania Trucks\n",
    "\n",
    "It seems like a lot of the classification tasks worth pursuing have low (< 5%) target prevalence, and in many of those tasks, there are a large number of both categorical and continuous predictors. In this notebook, I'll walk through a variety of approaches for dealing with unbalanced datasets.\n",
    "\n",
    "## Data Description\n",
    "`aps_failure_test_set.csv`: 11.9MB (16,000 obs)\n",
    "\n",
    "`aps_failure_training_set.csv`: 44.7MB (60,000 obs)\n",
    "\n",
    "The datasets' positive class consists of component failures for a specific component of the APS system. The negative class consists of trucks with failures for components not related to the APS.\n",
    "\n",
    "The attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like `Identifier_Bin`. In total there are 171 attributes, of which 7 are histogram variables. Missing values are denoted by `na`.\n",
    "\n",
    "## Challenge Metric\n",
    "Since this dataset was part of a challenge, they also provided a \"challenge metric\" formula to weight the cost of false positives and false negatives:\n",
    "\n",
    "`Cost_1(FP) = 10` and `cost_2(FN) = 500`\n",
    "\n",
    "We will want to minimize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_true, y_pred, fp_cost=10, fn_cost=500, normalize=True):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fp = cm[1][1]\n",
    "    fn = cm[0][1]\n",
    "    \n",
    "    c = fp * fp_cost + fn * fn_cost\n",
    "    \n",
    "    return c / len(y_true) if normalize else c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>76698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520.0</td>\n",
       "      <td>493384.0</td>\n",
       "      <td>721044.0</td>\n",
       "      <td>469792.0</td>\n",
       "      <td>339156.0</td>\n",
       "      <td>157956.0</td>\n",
       "      <td>73224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>33058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400.0</td>\n",
       "      <td>178064.0</td>\n",
       "      <td>293306.0</td>\n",
       "      <td>245416.0</td>\n",
       "      <td>133654.0</td>\n",
       "      <td>81140.0</td>\n",
       "      <td>97576.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>41040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.280000e+02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378.0</td>\n",
       "      <td>159812.0</td>\n",
       "      <td>423992.0</td>\n",
       "      <td>409564.0</td>\n",
       "      <td>320746.0</td>\n",
       "      <td>158022.0</td>\n",
       "      <td>95128.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>60874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.368000e+03</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012.0</td>\n",
       "      <td>229790.0</td>\n",
       "      <td>405298.0</td>\n",
       "      <td>347188.0</td>\n",
       "      <td>286954.0</td>\n",
       "      <td>311560.0</td>\n",
       "      <td>433954.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  aa_000  ab_000        ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
       "0   neg   76698     NaN  2.130706e+09   280.0     0.0     0.0     0.0     0.0   \n",
       "1   neg   33058     NaN  0.000000e+00     NaN     0.0     0.0     0.0     0.0   \n",
       "2   neg   41040     NaN  2.280000e+02   100.0     0.0     0.0     0.0     0.0   \n",
       "3   neg      12     0.0  7.000000e+01    66.0     0.0    10.0     0.0     0.0   \n",
       "4   neg   60874     NaN  1.368000e+03   458.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   ag_002  ...     ee_002    ee_003    ee_004    ee_005    ee_006    ee_007  \\\n",
       "0     0.0  ...  1240520.0  493384.0  721044.0  469792.0  339156.0  157956.0   \n",
       "1     0.0  ...   421400.0  178064.0  293306.0  245416.0  133654.0   81140.0   \n",
       "2     0.0  ...   277378.0  159812.0  423992.0  409564.0  320746.0  158022.0   \n",
       "3     0.0  ...      240.0      46.0      58.0      44.0      10.0       0.0   \n",
       "4     0.0  ...   622012.0  229790.0  405298.0  347188.0  286954.0  311560.0   \n",
       "\n",
       "     ee_008  ee_009  ef_000  eg_000  \n",
       "0   73224.0     0.0     0.0     0.0  \n",
       "1   97576.0  1500.0     0.0     0.0  \n",
       "2   95128.0   514.0     0.0     0.0  \n",
       "3       0.0     0.0     4.0    32.0  \n",
       "4  433954.0  1218.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('aps_failure_training_set.csv', header=14, na_values='na')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert target into a binary variable and rename column so it doesn't use a keyword (aka `class`) that prevents dot accessibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'] = train_df['class'].map({'neg': 0, 'pos': 1})\n",
    "train_df = train_df.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Generation\n",
    "I find it helpful to put together a metadata-set that describes important characteristics of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata(df):\n",
    "    meta = df.isnull().sum().to_frame('n_missing')\n",
    "    meta['perc_missing'] = meta['n_missing'] / len(df)\n",
    "    meta['n_unique'] = df.nunique()\n",
    "    \n",
    "    descs = train_df.describe().T\n",
    "    descs['n_valid'] = descs['count'].copy()\n",
    "    return meta.join(descs.drop('count', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = generate_metadata(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the cell below to view the metadata in its entirety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     display(meta.sort_values('perc_missing', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice about `meta`...\n",
    "\n",
    "- Everything is numeric. This is typical of UCI datasets, but normally, we would have to think about how to handle other types.\n",
    "- `cd_000` has only one unique value. We'll start by encoding it as a binary variable.\n",
    "\n",
    "For the baseline model, we will drop predictors that are over 25% missing and impute the median for the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove variables with > 25% missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_vars = meta[meta.perc_missing > 0.25].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.loc[:, ~train_df.columns.isin(bad_vars)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Dev Split\n",
    "We want to save the test set for an unbiased, out-of-sample assessment of the final model, so let's split the training data into a new training set and a development set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_data = train_test_split(train_df.drop('target', axis=1), train_df.target, test_size=.2, stratify=train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = golden_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a baseline model\n",
    "\n",
    "Let's start by getting a baseline model with logistic regression with L1 and L2 regularization (default in `sklearn`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('lr', LogisticRegression(solver='lbfgs', random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(pl, data):\n",
    "    X_train, X_dev, y_train, y_dev = data\n",
    "    \n",
    "    pl.fit(X_train, y_train)\n",
    "    \n",
    "    # train assessment\n",
    "    y_preds = pl.predict(X_train)\n",
    "    print('##### Train #####')\n",
    "    print(classification_report(y_train, y_preds))\n",
    "    print(f'Normalized train cost: {cost(y_train, y_preds):.{2}f}\\n')\n",
    "    \n",
    "    # dev assessment\n",
    "    y_preds = pl.predict(X_dev)\n",
    "    print('##### Test #####')\n",
    "    print(classification_report(y_dev, y_preds))\n",
    "    print(f'Normalized dev cost: {cost(y_dev, y_preds):.{2}f}\\n')\n",
    "    \n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     47200\n",
      "           1       0.86      0.68      0.76       800\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     48000\n",
      "   macro avg       0.93      0.84      0.88     48000\n",
      "weighted avg       0.99      0.99      0.99     48000\n",
      "\n",
      "Normalized train cost: 1.03\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     11800\n",
      "           1       0.80      0.66      0.73       200\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.90      0.83      0.86     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n",
      "Normalized dev cost: 1.44\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our baseline normalized cost for on the `dev` set is 1.44. Let's see if we can beat it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: ElasticNet\n",
    "I'm always confused about the difference between elastic net and logistic regression in `sklearn` because the logistic regression uses L1 and L2 regularization by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='elasticnet', random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     47200\n",
      "           1       0.73      0.63      0.67       800\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     48000\n",
      "   macro avg       0.86      0.81      0.83     48000\n",
      "weighted avg       0.99      0.99      0.99     48000\n",
      "\n",
      "Normalized train cost: 2.07\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11800\n",
      "           1       0.68      0.60      0.64       200\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.84      0.80      0.82     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n",
      "Normalized dev cost: 2.43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet + Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='elasticnet', learning_rate='adaptive', eta0=1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     47200\n",
      "           1       0.81      0.14      0.24       800\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     48000\n",
      "   macro avg       0.90      0.57      0.62     48000\n",
      "weighted avg       0.98      0.99      0.98     48000\n",
      "\n",
      "Normalized train cost: 0.31\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11800\n",
      "           1       0.78      0.15      0.26       200\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.88      0.58      0.63     12000\n",
      "weighted avg       0.98      0.99      0.98     12000\n",
      "\n",
      "Normalized dev cost: 0.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='l1', random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     47200\n",
      "           1       0.77      0.70      0.73       800\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     48000\n",
      "   macro avg       0.88      0.85      0.86     48000\n",
      "weighted avg       0.99      0.99      0.99     48000\n",
      "\n",
      "Normalized train cost: 1.89\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11800\n",
      "           1       0.70      0.64      0.67       200\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.85      0.82      0.83     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n",
      "Normalized dev cost: 2.36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Regularization + Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='l1', learning_rate='adaptive', eta0=1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     47200\n",
      "           1       0.85      0.43      0.57       800\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     48000\n",
      "   macro avg       0.92      0.72      0.78     48000\n",
      "weighted avg       0.99      0.99      0.99     48000\n",
      "\n",
      "Normalized train cost: 0.73\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11800\n",
      "           1       0.83      0.40      0.54       200\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.91      0.70      0.76     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n",
      "Normalized dev cost: 0.73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting....the L1-only model gives very similar results for both the train and dev sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Penality only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='l2', random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     47200\n",
      "           1       0.76      0.61      0.68       800\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     48000\n",
      "   macro avg       0.88      0.80      0.84     48000\n",
      "weighted avg       0.99      0.99      0.99     48000\n",
      "\n",
      "Normalized train cost: 1.74\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11800\n",
      "           1       0.69      0.59      0.64       200\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.84      0.79      0.82     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n",
      "Normalized dev cost: 2.31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Penality + Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='l2', learning_rate='adaptive', eta0=1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     47200\n",
      "           1       0.70      0.13      0.22       800\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     48000\n",
      "   macro avg       0.84      0.56      0.60     48000\n",
      "weighted avg       0.98      0.98      0.98     48000\n",
      "\n",
      "Normalized train cost: 0.47\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11800\n",
      "           1       0.71      0.16      0.26       200\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     12000\n",
      "   macro avg       0.85      0.58      0.63     12000\n",
      "weighted avg       0.98      0.98      0.98     12000\n",
      "\n",
      "Normalized dev cost: 0.57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No regularization + Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('en', SGDClassifier(loss='log', penalty='none', learning_rate='adaptive', eta0=1, random_state=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     47200\n",
      "           1       0.81      0.36      0.50       800\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     48000\n",
      "   macro avg       0.90      0.68      0.75     48000\n",
      "weighted avg       0.99      0.99      0.99     48000\n",
      "\n",
      "Normalized train cost: 0.78\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11800\n",
      "           1       0.72      0.34      0.47       200\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.85      0.67      0.73     12000\n",
      "weighted avg       0.98      0.99      0.98     12000\n",
      "\n",
      "Normalized dev cost: 1.18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The elastic net model with learning rate adaptation significantly outperformed the baseline model based on the challenge metric. However, I am having some heartburn about the whole challenge metric optimization...is a false  positive really 50 times worse than a false negative???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     47200\n",
      "           1       1.00      0.97      0.98       800\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     48000\n",
      "   macro avg       1.00      0.98      0.99     48000\n",
      "weighted avg       1.00      1.00      1.00     48000\n",
      "\n",
      "Normalized train cost: 0.17\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     11800\n",
      "           1       0.83      0.64      0.72       200\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.91      0.82      0.86     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n",
      "Normalized dev cost: 1.23\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('en', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None,...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm...this is the largest disparity in train/test cost that we've seen so far, which makes me think the model is overfit. I wonder if a RF would do better if we did some feature selection first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(np.nan, strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('selector', SelectFromModel(SGDClassifier(loss='log', penalty='elasticnet', learning_rate='adaptive', eta0=1, random_state=seed), )),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     47200\n",
      "           1       1.00      0.97      0.98       800\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     48000\n",
      "   macro avg       1.00      0.98      0.99     48000\n",
      "weighted avg       1.00      1.00      1.00     48000\n",
      "\n",
      "Normalized train cost: 0.17\n",
      "\n",
      "##### Test #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     11800\n",
      "           1       0.83      0.65      0.73       200\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     12000\n",
      "   macro avg       0.91      0.82      0.86     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n",
      "Normalized dev cost: 1.19\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('selector', SelectFromModel(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       ea...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = assess_model(pl, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature selection helped our testing performance a bit, but not by much. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
